{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"t6MPjfT5NrKQ"},"source":["# **ECE 565 Final Project - Real-Time 2D Object Detection (YOLO v5) Remember to connect a GPU before running the code**\n","\n","\n","‚ùóRemember to connect a GPU before running the code"]},{"cell_type":"markdown","source":["# **Step 1. Prepare codes and dataset**"],"metadata":{"id":"NVIhd4IrlkGT"}},{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["**Step 1.1 Mount your Google drive**"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aI3PJg2lJJwR","executionInfo":{"status":"ok","timestamp":1709404587195,"user_tz":360,"elapsed":15115,"user":{"displayName":"KSA IIT","userId":"13366027158898069714"}},"outputId":"e966041c-fb12-4cb2-b162-48c3a3ad8d05"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**Step 1.2 Set your project path**"],"metadata":{"id":"VFw-xROOJy-z"}},{"cell_type":"code","metadata":{"id":"wbvMlHd_QwMG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"68d9698a-b0d6-4a80-8e13-31c5c20f0ee4","executionInfo":{"status":"ok","timestamp":1709404620658,"user_tz":360,"elapsed":31099,"user":{"displayName":"KSA IIT","userId":"13366027158898069714"}}},"source":["%cd /content/drive/MyDrive/yolov5\n","%pip install -qr requirements.txt comet_ml  # install\n","\n","import torch\n","import utils\n","display = utils.notebook_init()  # checks"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["YOLOv5 üöÄ v7.0-288-gb9392361 Python-3.10.12 torch-2.1.0+cu121 CPU\n"]},{"output_type":"stream","name":"stdout","text":["Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 26.4/107.7 GB disk)\n"]}]},{"cell_type":"markdown","source":["**Step 1.3 Copy your dataset from your Google Drive to the cloud-based storage**\n","\n","Note: it helps accelerate fetching data when training, but all data stored on the cloud will be removed when closing the webpage"],"metadata":{"id":"2iD06IUeK9ee"}},{"cell_type":"code","source":["!cp -a '/content/drive/MyDrive/yolov5/datasets.zip' '/content'"],"metadata":{"id":"Cqav-pSaLBvB","executionInfo":{"status":"ok","timestamp":1709404965875,"user_tz":360,"elapsed":76752,"user":{"displayName":"KSA IIT","userId":"13366027158898069714"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**Step 1.4 Unzip the dataset**\n","\n","command \"-q\" hides the printing results"],"metadata":{"id":"QCnJ46z6LCWY"}},{"cell_type":"code","source":["!unzip -q /content/datasets.zip -d /content"],"metadata":{"id":"SN2mJEEbLFJM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Step 2. Train DABNet model using the PASCAL VOC dataset**"],"metadata":{"id":"hnHOM-96likK"}},{"cell_type":"markdown","metadata":{"id":"4JnkELT0cIJg"},"source":["**Step 2.1 Check the model connection**"]},{"cell_type":"code","metadata":{"id":"zR9ZbuQCH7FX"},"source":["!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images\n","display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZY2VXXXu74w5"},"source":["**Step 2.2 Train YOLO v5n model using the PASCAL VOC dataset**"]},{"cell_type":"code","metadata":{"id":"1NcFxRcFdJ_O"},"source":["#Usage - Single-GPU training:\n","\n","#!python train.py --data VOC.yaml --weights yolov5n.pt --cfg yolov5n.yaml # from pretrained (recommended)\n","#!python train.py --data VOC.yaml --weights '' --cfg yolov5n.yaml   # from scratch\n","\n","# Train YOLOv5n on PASCAL VOC for 30 epochs with pretrained yolov5n.pt\n","# If you face CUDA runtime error, change the batch_size to 64 or 32.\n","\n","!python train.py --data VOC.yaml --epochs 30 --weights yolov5n.pt --cfg yolov5n.yaml  --batch-size 128"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**(Optional)** resume training from the last saved trained model in case the training is interrupted.\n","\n","Your trained model is saved on runs train or val. Use it as a pretrained model."],"metadata":{"id":"hP2JHRpaLrBu"}},{"cell_type":"markdown","source":["# **Step 3 Evaluation**"],"metadata":{"id":"LvM0ssU3Lq3x"}},{"cell_type":"markdown","source":["**Check qualitative and quantitative results**\n","\n","*   Bring the best.pth(or last) file from \"weights\" for the evaluation\n","*   quantitave results with ground truth are stored in the \"run/exp\" folder\n","*   qualitative results with each category will be shown at the end\n","\n","\n","\n"],"metadata":{"id":"OPTli5b1lZ_u"}},{"cell_type":"code","source":["!python val.py --weights best.pt --data VOC.yaml\n"],"metadata":{"id":"R2sOtQklLpGd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**(Optional)** View Training log\n","\n","*   You can check \"iou_vs_epochs.png\" and \"loss_vs_epochs.png\" under the checkpoint/camvid/DABNetbs32gpu1_trainval folder\n","*   Note that the log only records the last training. If you resume your training, all the logs before resuming will not display\n","\n"],"metadata":{"id":"IK5Bd3SslNvD"}}]}